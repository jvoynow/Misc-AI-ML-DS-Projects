{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for Data: Tweets -> Int Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strings_to_ints(data):\n",
    "    unique_strings = []\n",
    "    new_data = []\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        if data[i] not in unique_strings:\n",
    "            unique_strings.append(data[i])\n",
    "            \n",
    "        for j in range(len(unique_strings)):\n",
    "            if unique_strings[j] == data[i]:\n",
    "                new_data.append(j)\n",
    "    \n",
    "    return np.array(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_word(word):\n",
    "    new_word = \"\"\n",
    "    for i in range(len(word)):\n",
    "        if word[i].isalnum():\n",
    "            new_word += word[i]\n",
    "    return new_word.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_data(raw_data):\n",
    "    clean_data = []\n",
    "    master_data_list = []\n",
    "    \n",
    "    for data in raw_data:\n",
    "        master_data_list.append(data.split())\n",
    "    \n",
    "    for data in master_data_list:\n",
    "        temp_data = []\n",
    "        for word in data:\n",
    "            new_word = preprocess_word(word)\n",
    "            if new_word != \"\":\n",
    "                temp_data.append(new_word)\n",
    "        clean_data.append(temp_data)\n",
    "    \n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_frequency(text_data):\n",
    "    frequency_dict = {}\n",
    "    \n",
    "    for data in text_data:\n",
    "        for word in data:\n",
    "            if word not in frequency_dict:\n",
    "                frequency_dict[word] = 1\n",
    "            else:\n",
    "                frequency_dict[word] += 1\n",
    "                \n",
    "    return frequency_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(vocab_size, clean_data):\n",
    "    words = [\"\"]\n",
    "    \n",
    "    word_frequency_dict = get_word_frequency(clean_data)\n",
    "    frequency_values = list(word_frequency_dict.values())\n",
    "    frequency_values.sort(reverse=True)\n",
    "    \n",
    "    count = vocab_size\n",
    "    while count > 0:\n",
    "        max_value = np.max(frequency_values)\n",
    "        for i in word_frequency_dict:\n",
    "            if word_frequency_dict[i] == max_value:\n",
    "                words.append(i)\n",
    "                break\n",
    "    \n",
    "        frequency_values.remove(max_value)\n",
    "        word_frequency_dict.pop(i)\n",
    "        count -= 1\n",
    "    \n",
    "    words.pop(0)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_to_vocab(words, clean_data):\n",
    "    input_data = np.zeros((len(clean_data), len(words)))\n",
    "    for i in range(len(clean_data)):\n",
    "        for j in range(len(words)):\n",
    "            input_data[i][j] = clean_data[i].count(words[j])\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('DemRepTweets.csv')\n",
    "data = df['Tweet'].values\n",
    "y = strings_to_ints(df['Party'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 500\n",
    "\n",
    "clean_data = get_clean_data(data)\n",
    "words = get_vocab(vocab_size, clean_data)\n",
    "x = fit_to_vocab(words, clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main: Models and Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67719 in 10.25 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "RF_1 = RandomForestClassifier(random_state=1, criterion='gini', max_features=8, n_estimators=25, n_jobs=-1)\n",
    "RF_1.fit(x_train, y_train)\n",
    "print(format(RF_1.score(x_test, y_test),'.5f'),\"in\",format(time.time() - start,'.2f'),\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67476 in 9.55 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "RF_2 = RandomForestClassifier(random_state=1, criterion='gini', max_depth=80, max_features=6, n_estimators=40, n_jobs=-1)\n",
    "RF_2.fit(x_train, y_train)\n",
    "print(format(RF_2.score(x_test, y_test),'.5f'),\"in\",format(time.time() - start,'.2f'),\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67222 in 11.36 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "RF_3 = RandomForestClassifier(random_state=1, criterion='entropy', max_features=8, n_estimators=25, n_jobs=-1)\n",
    "RF_3.fit(x_train, y_train)\n",
    "print(format(RF_3.score(x_test, y_test),'.5f'),\"in\",format(time.time() - start,'.2f'),\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67407 in 12.80 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "RF_4 = RandomForestClassifier(random_state=1, criterion='entropy', max_depth=80, max_features=6, n_estimators=40, n_jobs=-1)\n",
    "RF_4.fit(x_train, y_train)\n",
    "print(format(RF_4.score(x_test, y_test),'.5f'),\"in\",format(time.time() - start,'.2f'),\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    return [('rf_1',RF_1),('rf_2',RF_2),('rf_3',RF_3),('rf_4',RF_4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6924589405505436"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default voting classifier from sklearn\n",
    "\n",
    "ensemble_model = VotingClassifier(get_models(), voting='soft')\n",
    "ensemble_model.fit(x_train, y_train)\n",
    "ensemble_model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
